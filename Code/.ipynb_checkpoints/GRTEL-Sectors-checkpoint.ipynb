{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydateparser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "info = pd.read_csv('../data/snp_info.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_analysis = ['KO', 'TGT', 'PFE', 'MSFT', 'CVX', 'DVN', 'DAL', 'JPM', 'PEP', 'AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Communication Services</th>\n",
       "      <th>Consumer Discretionary</th>\n",
       "      <th>Consumer Staples</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Financials</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Industrials</th>\n",
       "      <th>Information Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>KO</td>\n",
       "      <td>MRO</td>\n",
       "      <td>BAC</td>\n",
       "      <td>PFE</td>\n",
       "      <td>GE</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TWTR</td>\n",
       "      <td>GM</td>\n",
       "      <td>KR</td>\n",
       "      <td>KMI</td>\n",
       "      <td>WFC</td>\n",
       "      <td>MRK</td>\n",
       "      <td>DAL</td>\n",
       "      <td>AMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB</td>\n",
       "      <td>EBAY</td>\n",
       "      <td>PG</td>\n",
       "      <td>XOM</td>\n",
       "      <td>C</td>\n",
       "      <td>GILD</td>\n",
       "      <td>CSX</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>SBUX</td>\n",
       "      <td>WMT</td>\n",
       "      <td>HAL</td>\n",
       "      <td>RF</td>\n",
       "      <td>BMY</td>\n",
       "      <td>AAL</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VZ</td>\n",
       "      <td>NKE</td>\n",
       "      <td>MDLZ</td>\n",
       "      <td>WMB</td>\n",
       "      <td>JPM</td>\n",
       "      <td>BSX</td>\n",
       "      <td>LUV</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>M</td>\n",
       "      <td>MO</td>\n",
       "      <td>COP</td>\n",
       "      <td>KEY</td>\n",
       "      <td>ABT</td>\n",
       "      <td>FAST</td>\n",
       "      <td>CSCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DIS</td>\n",
       "      <td>MGM</td>\n",
       "      <td>COTY</td>\n",
       "      <td>SLB</td>\n",
       "      <td>MS</td>\n",
       "      <td>CVS</td>\n",
       "      <td>CAT</td>\n",
       "      <td>HPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATVI</td>\n",
       "      <td>TJX</td>\n",
       "      <td>WBA</td>\n",
       "      <td>DVN</td>\n",
       "      <td>HBAN</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>JCI</td>\n",
       "      <td>ORCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IPG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>PM</td>\n",
       "      <td>CVX</td>\n",
       "      <td>SCHW</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>UAL</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DISCA</td>\n",
       "      <td>NWL</td>\n",
       "      <td>PEP</td>\n",
       "      <td>COG</td>\n",
       "      <td>SYF</td>\n",
       "      <td>MDT</td>\n",
       "      <td>UNP</td>\n",
       "      <td>AMAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Communication Services Consumer Discretionary Consumer Staples Energy  \\\n",
       "0                      T                      F               KO    MRO   \n",
       "1                   TWTR                     GM               KR    KMI   \n",
       "2                     FB                   EBAY               PG    XOM   \n",
       "3                  CMCSA                   SBUX              WMT    HAL   \n",
       "4                     VZ                    NKE             MDLZ    WMB   \n",
       "5                   NFLX                      M               MO    COP   \n",
       "6                    DIS                    MGM             COTY    SLB   \n",
       "7                   ATVI                    TJX              WBA    DVN   \n",
       "8                    IPG                    TGT               PM    CVX   \n",
       "9                  DISCA                    NWL              PEP    COG   \n",
       "\n",
       "  Financials Health Care Industrials Information Technology  \n",
       "0        BAC         PFE          GE                   AAPL  \n",
       "1        WFC         MRK         DAL                    AMD  \n",
       "2          C        GILD         CSX                     MU  \n",
       "3         RF         BMY         AAL                   MSFT  \n",
       "4        JPM         BSX         LUV                   INTC  \n",
       "5        KEY         ABT        FAST                   CSCO  \n",
       "6         MS         CVS         CAT                    HPE  \n",
       "7       HBAN        ABBV         JCI                   ORCL  \n",
       "8       SCHW         JNJ         UAL                   NVDA  \n",
       "9        SYF         MDT         UNP                   AMAT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv('stocks_by_sector.csv')\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_dict = {}\n",
    "for i in range(len(stocks.index)):\n",
    "    for j in range(len(stocks.columns)):\n",
    "        stock = stocks.iloc[i,j]\n",
    "        idx_dict[stock] = (i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "Get Samples and Labels\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Communication Services</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Information Technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asset</th>\n",
       "      <th colspan=\"8\" halign=\"left\">asset_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asset_2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asset_9</th>\n",
       "      <th colspan=\"8\" halign=\"left\">asset_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th>Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>k_percent</th>\n",
       "      <th>r_percent</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_EMA9</th>\n",
       "      <th>Price Rate Of Change</th>\n",
       "      <th>On Balance Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>Price Rate Of Change</th>\n",
       "      <th>On Balance Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>k_percent</th>\n",
       "      <th>r_percent</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_EMA9</th>\n",
       "      <th>Price Rate Of Change</th>\n",
       "      <th>On Balance Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>35.139999</td>\n",
       "      <td>66.984998</td>\n",
       "      <td>97.740062</td>\n",
       "      <td>-2.259938</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.047704</td>\n",
       "      <td>10592300</td>\n",
       "      <td>17.840000</td>\n",
       "      <td>30.079617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039824</td>\n",
       "      <td>-9242700</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>51.119297</td>\n",
       "      <td>43.165445</td>\n",
       "      <td>-56.834555</td>\n",
       "      <td>-0.097708</td>\n",
       "      <td>-0.124555</td>\n",
       "      <td>0.015485</td>\n",
       "      <td>-82509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>63.461411</td>\n",
       "      <td>78.712861</td>\n",
       "      <td>-21.287139</td>\n",
       "      <td>0.123844</td>\n",
       "      <td>0.042529</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>-19672100</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>23.781919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042453</td>\n",
       "      <td>-16010900</td>\n",
       "      <td>16.910000</td>\n",
       "      <td>47.801520</td>\n",
       "      <td>38.129494</td>\n",
       "      <td>-61.870506</td>\n",
       "      <td>-0.078060</td>\n",
       "      <td>-0.114917</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>-91721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-26</th>\n",
       "      <td>35.400002</td>\n",
       "      <td>68.861369</td>\n",
       "      <td>92.129714</td>\n",
       "      <td>-7.870286</td>\n",
       "      <td>0.170558</td>\n",
       "      <td>0.068877</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>22005000</td>\n",
       "      <td>17.010000</td>\n",
       "      <td>23.712060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049039</td>\n",
       "      <td>-10312300</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>57.746426</td>\n",
       "      <td>63.025232</td>\n",
       "      <td>-36.974768</td>\n",
       "      <td>-0.035484</td>\n",
       "      <td>-0.098570</td>\n",
       "      <td>0.035821</td>\n",
       "      <td>-75935100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-27</th>\n",
       "      <td>35.480000</td>\n",
       "      <td>69.888295</td>\n",
       "      <td>86.610888</td>\n",
       "      <td>-13.389112</td>\n",
       "      <td>0.209019</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>0.051571</td>\n",
       "      <td>72268000</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>21.997274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030759</td>\n",
       "      <td>-16104800</td>\n",
       "      <td>17.090000</td>\n",
       "      <td>51.107526</td>\n",
       "      <td>70.454523</td>\n",
       "      <td>-29.545477</td>\n",
       "      <td>-0.018663</td>\n",
       "      <td>-0.082221</td>\n",
       "      <td>0.054938</td>\n",
       "      <td>-88525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28</th>\n",
       "      <td>35.529999</td>\n",
       "      <td>70.587814</td>\n",
       "      <td>88.702907</td>\n",
       "      <td>-11.297093</td>\n",
       "      <td>0.239060</td>\n",
       "      <td>0.126372</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>98452400</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>19.903236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021625</td>\n",
       "      <td>-23024200</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>42.266121</td>\n",
       "      <td>47.976887</td>\n",
       "      <td>-52.023113</td>\n",
       "      <td>-0.031403</td>\n",
       "      <td>-0.071871</td>\n",
       "      <td>-0.007733</td>\n",
       "      <td>-106022400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sector     Communication Services                                             \\\n",
       "Asset                     asset_1                                              \n",
       "Metrics                     Close        RSI  k_percent  r_percent      MACD   \n",
       "Date                                                                           \n",
       "2016-01-22              35.139999  66.984998  97.740062  -2.259938  0.092199   \n",
       "2016-01-25              35.000000  63.461411  78.712861 -21.287139  0.123844   \n",
       "2016-01-26              35.400002  68.861369  92.129714  -7.870286  0.170558   \n",
       "2016-01-27              35.480000  69.888295  86.610888 -13.389112  0.209019   \n",
       "2016-01-28              35.529999  70.587814  88.702907 -11.297093  0.239060   \n",
       "\n",
       "Sector                                                                  \\\n",
       "Asset                                                          asset_2   \n",
       "Metrics    MACD_EMA9 Price Rate Of Change On Balance Volume      Close   \n",
       "Date                                                                     \n",
       "2016-01-22  0.021266             0.047704          10592300  17.840000   \n",
       "2016-01-25  0.042529             0.030928         -19672100  17.020000   \n",
       "2016-01-26  0.068877             0.044248          22005000  17.010000   \n",
       "2016-01-27  0.097551             0.051571          72268000  16.780001   \n",
       "2016-01-28  0.126372             0.035860          98452400  16.490000   \n",
       "\n",
       "Sector                 ... Information Technology                    \\\n",
       "Asset                  ...                asset_9                     \n",
       "Metrics           RSI  ...   Price Rate Of Change On Balance Volume   \n",
       "Date                   ...                                            \n",
       "2016-01-22  30.079617  ...              -0.039824          -9242700   \n",
       "2016-01-25  23.781919  ...              -0.042453         -16010900   \n",
       "2016-01-26  23.712060  ...              -0.049039         -10312300   \n",
       "2016-01-27  21.997274  ...              -0.030759         -16104800   \n",
       "2016-01-28  19.903236  ...              -0.021625         -23024200   \n",
       "\n",
       "Sector                                                                      \\\n",
       "Asset        asset_10                                                        \n",
       "Metrics         Close        RSI  k_percent  r_percent      MACD MACD_EMA9   \n",
       "Date                                                                         \n",
       "2016-01-22  17.049999  51.119297  43.165445 -56.834555 -0.097708 -0.124555   \n",
       "2016-01-25  16.910000  47.801520  38.129494 -61.870506 -0.078060 -0.114917   \n",
       "2016-01-26  17.350000  57.746426  63.025232 -36.974768 -0.035484 -0.098570   \n",
       "2016-01-27  17.090000  51.107526  70.454523 -29.545477 -0.018663 -0.082221   \n",
       "2016-01-28  16.680000  42.266121  47.976887 -52.023113 -0.031403 -0.071871   \n",
       "\n",
       "Sector                                             \n",
       "Asset                                              \n",
       "Metrics    Price Rate Of Change On Balance Volume  \n",
       "Date                                               \n",
       "2016-01-22             0.015485         -82509700  \n",
       "2016-01-25             0.013789         -91721800  \n",
       "2016-01-26             0.035821         -75935100  \n",
       "2016-01-27             0.054938         -88525300  \n",
       "2016-01-28            -0.007733        -106022400  \n",
       "\n",
       "[5 rows x 640 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.read_csv('samples_sector.csv', index_col=0, header=[0,1,2], parse_dates=True, date_parser=mydateparser)\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TWTR</th>\n",
       "      <th>FB</th>\n",
       "      <th>CMCSA</th>\n",
       "      <th>VZ</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>IPG</th>\n",
       "      <th>DISCA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMD</th>\n",
       "      <th>MU</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>INTC</th>\n",
       "      <th>CSCO</th>\n",
       "      <th>HPE</th>\n",
       "      <th>ORCL</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>AMAT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              T  TWTR   FB  CMCSA   VZ  NFLX  DIS  ATVI  IPG  DISCA  ...  \\\n",
       "Date                                                                 ...   \n",
       "2016-01-22  1.0   0.0  1.0    1.0  1.0   0.0  0.0   0.0  0.0    1.0  ...   \n",
       "2016-01-25  1.0   0.0  1.0    1.0  1.0   0.0  0.0   0.0  0.0    1.0  ...   \n",
       "2016-01-26  1.0   0.0  1.0    1.0  1.0   0.0  0.0   0.0  0.0    0.0  ...   \n",
       "2016-01-27  1.0   0.0  1.0    1.0  1.0   0.0  0.0   0.0  0.0    0.0  ...   \n",
       "2016-01-28  1.0   0.0  0.0    1.0  1.0   0.0  0.0   0.0  0.0    0.0  ...   \n",
       "\n",
       "            AAPL  AMD   MU  MSFT  INTC  CSCO  HPE  ORCL  NVDA  AMAT  \n",
       "Date                                                                 \n",
       "2016-01-22   0.0  1.0  1.0   0.0   0.0   1.0  1.0   1.0   0.0   1.0  \n",
       "2016-01-25   0.0  0.0  1.0   0.0   0.0   0.0  0.0   1.0   0.0   0.0  \n",
       "2016-01-26   0.0  0.0  0.0   0.0   0.0   0.0  0.0   1.0   0.0   0.0  \n",
       "2016-01-27   1.0  0.0  0.0   0.0   0.0   0.0  0.0   1.0   0.0   0.0  \n",
       "2016-01-28   1.0  0.0  1.0   0.0   0.0   0.0  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels_sector.csv', index_col='Date', parse_dates=True, date_parser=mydateparser)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "Tensor Ensemble Learning\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GRTEL.decomposition import GLTD\n",
    "from GRTEL.utils import downturn_confidence, print_scores, print_1_percentage\n",
    "from GRTEL.classification import GRTEL\n",
    "\n",
    "from hottbox.core import Tensor, TensorTKD\n",
    "from hottbox.pdtools import pd_to_tensor\n",
    "from hottbox.algorithms.decomposition import HOSVD, HOOI\n",
    "from hottbox.utils.generation import residual_tensor\n",
    "from hottbox.algorithms.classification import TelVI\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tensor is of order 3 and consists of 640 elements.\n",
      "Sizes and names of its modes are (8, 10, 8) and ['Metrics', 'Asset', 'Sector'] respectively. \n",
      "\n",
      " [1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(samples)):\n",
    "    X_t = samples.iloc[i].reorder_levels(['Metrics', 'Asset', 'Sector']) #Make 'Sector' the third mode of the tensor\n",
    "    X.append(pd_to_tensor(X_t))\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "print(X[0], '\\n\\n', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atayardimci/opt/anaconda3/lib/python3.8/site-packages/hottbox/algorithms/decomposition/base.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "  S = np.sqrt(S)\n"
     ]
    }
   ],
   "source": [
    "# Represent each sample in Tucker form and store it in a list\n",
    "algo = HOOI()\n",
    "# algo = GLTD()\n",
    "rank = (4,3,3)\n",
    "X_tk = [algo.decompose(sample, rank=rank) for sample in X]\n",
    "\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tk, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# test_size = 0.25\n",
    "# k = int(len(X_tk) * (1. - test_size))\n",
    "\n",
    "# X_train, X_test = X_tk[:k], X_tk[k:]\n",
    "# y_train, y_test = y[:k], y[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d4b4232e0965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#Scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrtel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nClassification accuracy (Train):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GR-TEL-for-Financial-Forecasting/Code/GRTEL/classification.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hottbox/algorithms/classification/ensemble_learning.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTelVI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hottbox/algorithms/classification/ensemble_learning.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mpred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proba_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hottbox/algorithms/classification/ensemble_learning.py\u001b[0m in \u001b[0;36m_proba_to_label\u001b[0;34m(self, pred_proba)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m    350\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_clf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "# Initialise classifier\n",
    "R = np.sum(rank) # number of base classifiers required per class\n",
    "n_classes = 1 if y.ndim == 1 else y.shape[1]\n",
    "\n",
    "base_clfs = []\n",
    "for _ in range(n_classes):\n",
    "    base_clfs.append([DecisionTreeClassifier() for _ in range(R)])\n",
    "\n",
    "grtel = GRTEL(base_clfs=base_clfs,\n",
    "              n_classes=n_classes,\n",
    "              probability=True,\n",
    "              verbose=False)\n",
    "\n",
    "\n",
    "# Train classifer\n",
    "grtel.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Scores\n",
    "score = grtel.score(X_train, y_train)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"\\nClassification accuracy (Train):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "score = grtel.score(X_test, y_test)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Test):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "print(\"Percentage of 1s (Test):\")\n",
    "print_1_percentage(y_test, n_classes); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(104, 82, 0.7884615384615384),\n",
       " (71, 48, 0.676056338028169),\n",
       " (59, 42, 0.711864406779661),\n",
       " (65, 45, 0.6923076923076923),\n",
       " (101, 76, 0.7524752475247525),\n",
       " (57, 46, 0.8070175438596491),\n",
       " (84, 64, 0.7619047619047619),\n",
       " (73, 59, 0.8082191780821918),\n",
       " (109, 76, 0.6972477064220184),\n",
       " (128, 82, 0.640625),\n",
       " (123, 82, 0.6666666666666666),\n",
       " (105, 73, 0.6952380952380952),\n",
       " (87, 56, 0.6436781609195402),\n",
       " (88, 65, 0.7386363636363636),\n",
       " (103, 71, 0.6893203883495146),\n",
       " (115, 78, 0.6782608695652174),\n",
       " (62, 45, 0.7258064516129032),\n",
       " (82, 58, 0.7073170731707317),\n",
       " (94, 66, 0.7021276595744681),\n",
       " (96, 66, 0.6875),\n",
       " (71, 56, 0.7887323943661971),\n",
       " (96, 70, 0.7291666666666666),\n",
       " (70, 49, 0.7),\n",
       " (52, 37, 0.7115384615384616),\n",
       " (79, 65, 0.8227848101265823),\n",
       " (89, 67, 0.7528089887640449),\n",
       " (140, 93, 0.6642857142857143),\n",
       " (90, 71, 0.7888888888888889),\n",
       " (66, 58, 0.8787878787878788),\n",
       " (69, 54, 0.782608695652174),\n",
       " (97, 71, 0.7319587628865979),\n",
       " (116, 84, 0.7241379310344828),\n",
       " (79, 59, 0.7468354430379747),\n",
       " (92, 74, 0.8043478260869565),\n",
       " (85, 56, 0.6588235294117647),\n",
       " (84, 65, 0.7738095238095238),\n",
       " (126, 89, 0.7063492063492064),\n",
       " (112, 79, 0.7053571428571429),\n",
       " (87, 64, 0.735632183908046),\n",
       " (76, 58, 0.7631578947368421),\n",
       " (63, 48, 0.7619047619047619),\n",
       " (103, 72, 0.6990291262135923),\n",
       " (69, 59, 0.855072463768116),\n",
       " (75, 56, 0.7466666666666667),\n",
       " (68, 56, 0.8235294117647058),\n",
       " (75, 61, 0.8133333333333334),\n",
       " (71, 54, 0.7605633802816901),\n",
       " (68, 57, 0.8382352941176471),\n",
       " (75, 56, 0.7466666666666667),\n",
       " (103, 68, 0.6601941747572816),\n",
       " (70, 51, 0.7285714285714285),\n",
       " (83, 66, 0.7951807228915663),\n",
       " (111, 79, 0.7117117117117117),\n",
       " (87, 67, 0.7701149425287356),\n",
       " (43, 35, 0.813953488372093),\n",
       " (50, 37, 0.74),\n",
       " (109, 77, 0.7064220183486238),\n",
       " (68, 48, 0.7058823529411765),\n",
       " (70, 55, 0.7857142857142857),\n",
       " (75, 54, 0.72),\n",
       " (144, 104, 0.7222222222222222),\n",
       " (78, 58, 0.7435897435897436),\n",
       " (64, 42, 0.65625),\n",
       " (87, 67, 0.7701149425287356),\n",
       " (76, 56, 0.7368421052631579),\n",
       " (89, 66, 0.7415730337078652),\n",
       " (59, 41, 0.6949152542372882),\n",
       " (73, 56, 0.7671232876712328),\n",
       " (74, 58, 0.7837837837837838),\n",
       " (81, 53, 0.654320987654321),\n",
       " (63, 54, 0.8571428571428571),\n",
       " (53, 41, 0.7735849056603774),\n",
       " (55, 42, 0.7636363636363637),\n",
       " (47, 33, 0.7021276595744681),\n",
       " (66, 57, 0.8636363636363636),\n",
       " (60, 44, 0.7333333333333333),\n",
       " (78, 60, 0.7692307692307693),\n",
       " (65, 48, 0.7384615384615385),\n",
       " (45, 36, 0.8),\n",
       " (55, 42, 0.7636363636363637)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(n_classes):\n",
    "    results.append(downturn_confidence(y_test[:,i], grtel.models[i].predict(X_test)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(267, 267, 1.0),\n",
       " (256, 256, 1.0),\n",
       " (223, 223, 1.0),\n",
       " (235, 235, 1.0),\n",
       " (259, 259, 1.0),\n",
       " (228, 228, 1.0),\n",
       " (255, 255, 1.0),\n",
       " (240, 240, 1.0),\n",
       " (272, 272, 1.0),\n",
       " (288, 288, 1.0),\n",
       " (304, 304, 1.0),\n",
       " (291, 291, 1.0),\n",
       " (254, 254, 1.0),\n",
       " (248, 248, 1.0),\n",
       " (267, 267, 1.0),\n",
       " (286, 286, 1.0),\n",
       " (228, 228, 1.0),\n",
       " (241, 241, 1.0),\n",
       " (267, 267, 1.0),\n",
       " (280, 280, 1.0),\n",
       " (233, 233, 1.0),\n",
       " (279, 279, 1.0),\n",
       " (238, 238, 1.0),\n",
       " (222, 222, 1.0),\n",
       " (249, 249, 1.0),\n",
       " (265, 265, 1.0),\n",
       " (327, 327, 1.0),\n",
       " (246, 246, 1.0),\n",
       " (234, 234, 1.0),\n",
       " (246, 246, 1.0),\n",
       " (281, 281, 1.0),\n",
       " (280, 280, 1.0),\n",
       " (265, 265, 1.0),\n",
       " (280, 280, 1.0),\n",
       " (275, 275, 1.0),\n",
       " (258, 258, 1.0),\n",
       " (298, 298, 1.0),\n",
       " (291, 291, 1.0),\n",
       " (245, 245, 1.0),\n",
       " (257, 257, 1.0),\n",
       " (230, 230, 1.0),\n",
       " (272, 272, 1.0),\n",
       " (254, 254, 1.0),\n",
       " (241, 241, 1.0),\n",
       " (235, 235, 1.0),\n",
       " (255, 255, 1.0),\n",
       " (250, 250, 1.0),\n",
       " (234, 234, 1.0),\n",
       " (236, 236, 1.0),\n",
       " (280, 280, 1.0),\n",
       " (242, 242, 1.0),\n",
       " (238, 238, 1.0),\n",
       " (281, 281, 1.0),\n",
       " (239, 239, 1.0),\n",
       " (197, 197, 1.0),\n",
       " (214, 214, 1.0),\n",
       " (272, 272, 1.0),\n",
       " (239, 239, 1.0),\n",
       " (235, 235, 1.0),\n",
       " (248, 248, 1.0),\n",
       " (343, 343, 1.0),\n",
       " (254, 254, 1.0),\n",
       " (213, 213, 1.0),\n",
       " (260, 260, 1.0),\n",
       " (244, 244, 1.0),\n",
       " (248, 248, 1.0),\n",
       " (220, 220, 1.0),\n",
       " (257, 257, 1.0),\n",
       " (226, 226, 1.0),\n",
       " (226, 226, 1.0),\n",
       " (209, 209, 1.0),\n",
       " (209, 209, 1.0),\n",
       " (230, 230, 1.0),\n",
       " (200, 200, 1.0),\n",
       " (227, 227, 1.0),\n",
       " (212, 212, 1.0),\n",
       " (246, 246, 1.0),\n",
       " (231, 231, 1.0),\n",
       " (204, 204, 1.0),\n",
       " (225, 225, 1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(n_classes):\n",
    "    results.append(downturn_confidence(y_train[:,i], grtel.models[i].predict(X_train)))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "Grid Search\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPerforming grid search for each base classifer and for each class\n",
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - \n",
      "\tTrain base classifiers with optimal hyperparameters\n",
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - \n",
      "\n",
      "Classification accuracy (Train):\n",
      "[100.00%, 99.64%, 99.64%, 100.00%, 99.82%, 99.82%, 100.00%, 100.00%, 100.00%, 99.45%, 99.27%, 100.00%, 100.00%, 100.00%, 98.91%, 100.00%, 99.45%, 99.64%, 100.00%, 99.64%, 99.64%, 98.00%, 100.00%, 97.27%, 99.27%, 99.82%, 99.82%, 99.64%, 99.82%, 100.00%, 99.45%, 99.82%, 99.45%, 99.82%, 100.00%, 98.36%, 100.00%, 99.64%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 99.64%, 99.09%, 100.00%, 96.72%, 99.64%, 99.64%, 99.45%, 98.91%, 100.00%, 99.64%, 100.00%, 99.82%, 100.00%, 99.82%, 99.82%, 100.00%, 99.64%, 99.82%, 99.64%, 100.00%, 100.00%, 95.81%, 100.00%, 100.00%, 98.91%, 98.91%, 99.09%, 99.82%, 100.00%, 99.82%, 99.09%, 99.64%, 100.00%, 98.72%, 99.64%, 99.27%]\n",
      "\n",
      "Classification accuracy (Test):\n",
      "[75.96%, 66.67%, 66.67%, 70.49%, 71.04%, 74.32%, 69.40%, 70.49%, 68.85%, 65.57%, 71.58%, 79.78%, 68.31%, 78.14%, 69.95%, 73.77%, 68.31%, 70.49%, 65.57%, 67.21%, 77.60%, 72.68%, 78.14%, 72.13%, 68.31%, 76.50%, 74.32%, 68.31%, 71.58%, 77.60%, 79.78%, 77.05%, 75.96%, 82.51%, 66.67%, 80.33%, 75.41%, 74.32%, 78.14%, 69.95%, 77.05%, 72.68%, 73.77%, 76.50%, 75.96%, 73.22%, 72.68%, 69.40%, 75.41%, 74.32%, 65.57%, 72.68%, 72.68%, 78.69%, 73.77%, 68.31%, 74.32%, 75.41%, 77.05%, 68.85%, 74.32%, 72.68%, 76.50%, 79.78%, 76.50%, 71.04%, 73.77%, 76.50%, 73.22%, 66.67%, 71.58%, 70.49%, 72.13%, 67.76%, 69.95%, 71.58%, 75.41%, 72.68%, 76.50%, 79.78%]\n",
      "\n",
      "Percentage of 1s (Test):\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "print_1_percentage() missing 1 required positional argument: 'n_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ac51b8de99cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Percentage of 1s (Test):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint_1_percentage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_1_percentage() missing 1 required positional argument: 'n_classes'"
     ]
    }
   ],
   "source": [
    "max_features = ['auto', 'sqrt', None, 'log2']\n",
    "max_depth = list(range(10, 70, 10))\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 20, 30]\n",
    "min_samples_leaf = [1, 3, 5, 7, 12, 14]\n",
    "\n",
    "search_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "search_params = [search_grid for _ in range(R)]\n",
    "\n",
    "print(\"\\tPerforming grid search for each base classifer and for each class\")\n",
    "grtel.grid_search(X_train, y_train, search_params)\n",
    "\n",
    "print(\"\\tTrain base classifiers with optimal hyperparameters\")\n",
    "grtel.fit(X_train, y_train); print()\n",
    "\n",
    "score = grtel.score(X_train, y_train)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Train):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "score = grtel.score(X_test, y_test)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Test):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "print(\"Percentage of 1s (Test):\")\n",
    "print_1_percentage(y_test, n_classes); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(98, 75, 0.7653061224489796),\n",
       " (74, 42, 0.5675675675675675),\n",
       " (56, 37, 0.6607142857142857),\n",
       " (70, 45, 0.6428571428571429),\n",
       " (110, 79, 0.7181818181818181),\n",
       " (73, 49, 0.6712328767123288),\n",
       " (86, 61, 0.7093023255813954),\n",
       " (68, 49, 0.7205882352941176),\n",
       " (122, 81, 0.6639344262295082),\n",
       " (137, 84, 0.6131386861313869),\n",
       " (130, 79, 0.6076923076923076),\n",
       " (105, 80, 0.7619047619047619),\n",
       " (87, 59, 0.6781609195402298),\n",
       " (102, 73, 0.7156862745098039),\n",
       " (92, 59, 0.6413043478260869),\n",
       " (131, 83, 0.6335877862595419),\n",
       " (62, 41, 0.6612903225806451),\n",
       " (86, 60, 0.6976744186046512),\n",
       " (99, 62, 0.6262626262626263),\n",
       " (125, 74, 0.592),\n",
       " (86, 59, 0.686046511627907),\n",
       " (122, 75, 0.6147540983606558),\n",
       " (62, 46, 0.7419354838709677),\n",
       " (44, 30, 0.6818181818181818),\n",
       " (79, 59, 0.7468354430379747),\n",
       " (82, 58, 0.7073170731707317),\n",
       " (143, 89, 0.6223776223776224),\n",
       " (95, 68, 0.7157894736842105),\n",
       " (52, 45, 0.8653846153846154),\n",
       " (66, 52, 0.7878787878787878),\n",
       " (113, 74, 0.6548672566371682),\n",
       " (120, 81, 0.675),\n",
       " (91, 63, 0.6923076923076923),\n",
       " (113, 80, 0.7079646017699115),\n",
       " (99, 61, 0.6161616161616161),\n",
       " (71, 54, 0.7605633802816901),\n",
       " (134, 90, 0.6716417910447762),\n",
       " (123, 76, 0.6178861788617886),\n",
       " (80, 61, 0.7625),\n",
       " (65, 51, 0.7846153846153846),\n",
       " (69, 49, 0.7101449275362319),\n",
       " (99, 64, 0.6464646464646465),\n",
       " (80, 59, 0.7375),\n",
       " (62, 47, 0.7580645161290323),\n",
       " (74, 53, 0.7162162162162162),\n",
       " (72, 55, 0.7638888888888888),\n",
       " (77, 51, 0.6623376623376623),\n",
       " (53, 39, 0.7358490566037735),\n",
       " (62, 45, 0.7258064516129032),\n",
       " (110, 66, 0.6),\n",
       " (69, 45, 0.6521739130434783),\n",
       " (80, 59, 0.7375),\n",
       " (132, 82, 0.6212121212121212),\n",
       " (77, 61, 0.7922077922077922),\n",
       " (38, 29, 0.7631578947368421),\n",
       " (57, 40, 0.7017543859649122),\n",
       " (99, 69, 0.696969696969697),\n",
       " (73, 53, 0.726027397260274),\n",
       " (72, 56, 0.7777777777777778),\n",
       " (84, 55, 0.6547619047619048),\n",
       " (147, 104, 0.7074829931972789),\n",
       " (91, 62, 0.6813186813186813),\n",
       " (64, 44, 0.6875),\n",
       " (81, 69, 0.8518518518518519),\n",
       " (68, 51, 0.75),\n",
       " (84, 55, 0.6547619047619048),\n",
       " (63, 41, 0.6507936507936508),\n",
       " (79, 56, 0.7088607594936709),\n",
       " (74, 58, 0.7837837837837838),\n",
       " (66, 45, 0.6818181818181818),\n",
       " (51, 39, 0.7647058823529411),\n",
       " (52, 35, 0.6730769230769231),\n",
       " (53, 39, 0.7358490566037735),\n",
       " (42, 29, 0.6904761904761905),\n",
       " (58, 45, 0.7758620689655172),\n",
       " (57, 39, 0.6842105263157895),\n",
       " (76, 59, 0.7763157894736842),\n",
       " (74, 54, 0.7297297297297297),\n",
       " (40, 31, 0.775),\n",
       " (50, 38, 0.76)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(n_classes):\n",
    "    results.append(downturn_confidence(y_test[:,i], grtel.models[i].predict(X_test)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(270, 266, 0.9851851851851852),\n",
       " (260, 250, 0.9615384615384616),\n",
       " (228, 218, 0.956140350877193),\n",
       " (235, 235, 1.0),\n",
       " (267, 259, 0.9700374531835206),\n",
       " (228, 226, 0.9912280701754386),\n",
       " (256, 252, 0.984375),\n",
       " (239, 239, 1.0),\n",
       " (281, 272, 0.9679715302491103),\n",
       " (316, 287, 0.9082278481012658),\n",
       " (324, 304, 0.9382716049382716),\n",
       " (295, 291, 0.9864406779661017),\n",
       " (256, 252, 0.984375),\n",
       " (249, 248, 0.9959839357429718),\n",
       " (276, 261, 0.9456521739130435),\n",
       " (286, 286, 1.0),\n",
       " (229, 224, 0.9781659388646288),\n",
       " (243, 238, 0.9794238683127572),\n",
       " (267, 266, 0.9962546816479401),\n",
       " (328, 280, 0.8536585365853658),\n",
       " (229, 228, 0.9956331877729258),\n",
       " (314, 276, 0.8789808917197452),\n",
       " (239, 238, 0.99581589958159),\n",
       " (200, 197, 0.985),\n",
       " (243, 236, 0.9711934156378601),\n",
       " (265, 264, 0.9962264150943396),\n",
       " (337, 326, 0.9673590504451038),\n",
       " (247, 244, 0.9878542510121457),\n",
       " (233, 231, 0.9914163090128756),\n",
       " (245, 242, 0.9877551020408163),\n",
       " (302, 281, 0.9304635761589404),\n",
       " (296, 280, 0.9459459459459459),\n",
       " (271, 264, 0.974169741697417),\n",
       " (300, 280, 0.9333333333333333),\n",
       " (278, 275, 0.9892086330935251),\n",
       " (262, 249, 0.950381679389313),\n",
       " (314, 298, 0.9490445859872612),\n",
       " (317, 291, 0.917981072555205),\n",
       " (246, 245, 0.9959349593495935),\n",
       " (256, 255, 0.99609375),\n",
       " (229, 228, 0.9956331877729258),\n",
       " (274, 272, 0.9927007299270073),\n",
       " (255, 254, 0.996078431372549),\n",
       " (241, 241, 1.0),\n",
       " (232, 231, 0.9956896551724138),\n",
       " (251, 244, 0.9721115537848606),\n",
       " (250, 250, 1.0),\n",
       " (201, 199, 0.9900497512437811),\n",
       " (227, 227, 1.0),\n",
       " (300, 280, 0.9333333333333333),\n",
       " (239, 235, 0.9832635983263598),\n",
       " (233, 229, 0.9828326180257511),\n",
       " (290, 281, 0.9689655172413794),\n",
       " (231, 230, 0.9956709956709957),\n",
       " (195, 195, 1.0),\n",
       " (212, 210, 0.9905660377358491),\n",
       " (271, 270, 0.996309963099631),\n",
       " (237, 236, 0.9957805907172996),\n",
       " (234, 231, 0.9871794871794872),\n",
       " (247, 246, 0.9959514170040485),\n",
       " (366, 343, 0.9371584699453552),\n",
       " (250, 249, 0.996),\n",
       " (209, 207, 0.9904306220095693),\n",
       " (258, 258, 1.0),\n",
       " (244, 244, 1.0),\n",
       " (245, 230, 0.9387755102040817),\n",
       " (220, 220, 1.0),\n",
       " (259, 254, 0.9806949806949807),\n",
       " (219, 216, 0.9863013698630136),\n",
       " (220, 217, 0.9863636363636363),\n",
       " (206, 203, 0.9854368932038835),\n",
       " (207, 205, 0.9903381642512077),\n",
       " (226, 225, 0.995575221238938),\n",
       " (196, 196, 1.0),\n",
       " (217, 214, 0.9861751152073732),\n",
       " (208, 206, 0.9903846153846154),\n",
       " (246, 245, 0.9959349593495935),\n",
       " (233, 223, 0.9570815450643777),\n",
       " (200, 194, 0.97),\n",
       " (218, 216, 0.9908256880733946)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(n_classes):\n",
    "    results.append(downturn_confidence(y_train[:,i], grtel.models[i].predict(X_train)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
