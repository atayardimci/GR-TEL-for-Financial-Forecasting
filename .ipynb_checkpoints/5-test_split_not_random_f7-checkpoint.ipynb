{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Set paths\n",
    "fig_path = './figures/'\n",
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Get the companies**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "mydateparser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "snp = pd.read_csv(data_path+\"snp_allstocks_2015_2019.csv\", index_col='Date', parse_dates=True, date_parser=mydateparser)\n",
    "info = pd.read_csv(data_path+'snp_info.csv', index_col=0)\n",
    "\n",
    "snp500 = pd.read_csv(data_path+\"snp_500_2015_2019.csv\", index_col='Date', parse_dates=True, date_parser=mydateparser)\n",
    "snp500 = snp500['Adj Close']\n",
    "\n",
    "# https://www.slickcharts.com/sp500\n",
    "# https://datahub.io/core/s-and-p-500-companies-financials\n",
    "detailed_info = pd.read_csv(data_path+'constituents-financials.csv', index_col=0)\n",
    "stocks_sorted = detailed_info.sort_values('Market Cap', ascending=False)['Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_by_sector = {sector: [] for sector in info['GICS Sector'].unique()}\n",
    "\n",
    "for stock in stocks_sorted.index[:160]:\n",
    "    if stock in ['PCLN', 'TWX', 'AET', 'MON', 'PX', 'ESRX']:\n",
    "        continue\n",
    "    stock = 'BRK-B' if stock == 'BRK.B' else stock\n",
    "    \n",
    "    sector = info.set_index('Symbol').loc[stock]['GICS Sector']\n",
    "    stocks_by_sector[sector].append(stock)\n",
    "# stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top three stocks (by market cap) within each GICS Sector\n",
    "stocks = {}\n",
    "for sector in stocks_by_sector:\n",
    "    stocks[sector] = stocks_by_sector[sector][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Communication Services': ['GOOGL', 'GOOG', 'FB'],\n",
       " 'Consumer Discretionary': ['AMZN', 'HD', 'MCD'],\n",
       " 'Financials': ['JPM', 'BAC', 'WFC'],\n",
       " 'Information Technology': ['AAPL', 'MSFT', 'V']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a subset of stocks instead for easy understanding\n",
    "# order them alphabetically\n",
    "tmp = {}\n",
    "tmp['Communication Services'] = stocks['Communication Services']\n",
    "tmp['Consumer Discretionary'] = stocks['Consumer Discretionary']\n",
    "tmp['Financials'] = stocks['Financials']\n",
    "tmp['Information Technology'] = stocks['Information Technology']\n",
    "\n",
    "stocks = tmp\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Get the data**\n",
    "------------------------------------\n",
    "- Standardize individual asset names (e.g. asset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_col = []\n",
    "stock_col = []\n",
    "for sector in stocks:\n",
    "    for i, stock in enumerate(stocks[sector]):\n",
    "        stock_name = 'asset_' + str(i+1)\n",
    "        sector_col.append(sector)\n",
    "        stock_col.append(stock_name)\n",
    "\n",
    "df = pd.DataFrame(columns=[sector_col, stock_col], index=snp.index)\n",
    "df.columns.names = ['Sector', 'Asset']\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Communication Services</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Consumer Discretionary</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Financials</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Information Technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asset</th>\n",
       "      <th>asset_1</th>\n",
       "      <th>asset_2</th>\n",
       "      <th>asset_3</th>\n",
       "      <th>asset_1</th>\n",
       "      <th>asset_2</th>\n",
       "      <th>asset_3</th>\n",
       "      <th>asset_1</th>\n",
       "      <th>asset_2</th>\n",
       "      <th>asset_3</th>\n",
       "      <th>asset_1</th>\n",
       "      <th>asset_2</th>\n",
       "      <th>asset_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>529.549988</td>\n",
       "      <td>521.937744</td>\n",
       "      <td>78.449997</td>\n",
       "      <td>308.519989</td>\n",
       "      <td>103.430000</td>\n",
       "      <td>93.260002</td>\n",
       "      <td>62.490002</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>54.700001</td>\n",
       "      <td>109.330002</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>66.254997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>519.460022</td>\n",
       "      <td>511.057617</td>\n",
       "      <td>77.190002</td>\n",
       "      <td>302.190002</td>\n",
       "      <td>101.260002</td>\n",
       "      <td>92.230003</td>\n",
       "      <td>60.549999</td>\n",
       "      <td>17.379999</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>46.330002</td>\n",
       "      <td>64.792503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>506.640015</td>\n",
       "      <td>499.212799</td>\n",
       "      <td>76.150002</td>\n",
       "      <td>295.290009</td>\n",
       "      <td>100.949997</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>58.980000</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>52.090000</td>\n",
       "      <td>106.260002</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>64.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>505.149994</td>\n",
       "      <td>498.357513</td>\n",
       "      <td>76.150002</td>\n",
       "      <td>298.420013</td>\n",
       "      <td>104.410004</td>\n",
       "      <td>94.010002</td>\n",
       "      <td>59.070000</td>\n",
       "      <td>16.940001</td>\n",
       "      <td>52.400002</td>\n",
       "      <td>107.750000</td>\n",
       "      <td>46.230000</td>\n",
       "      <td>65.237503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>506.910004</td>\n",
       "      <td>499.928864</td>\n",
       "      <td>78.180000</td>\n",
       "      <td>300.459991</td>\n",
       "      <td>106.720001</td>\n",
       "      <td>94.360001</td>\n",
       "      <td>60.389999</td>\n",
       "      <td>17.290001</td>\n",
       "      <td>53.560001</td>\n",
       "      <td>111.889999</td>\n",
       "      <td>47.590000</td>\n",
       "      <td>66.112503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sector     Communication Services                         \\\n",
       "Asset                     asset_1     asset_2    asset_3   \n",
       "Date                                                       \n",
       "2015-01-02             529.549988  521.937744  78.449997   \n",
       "2015-01-05             519.460022  511.057617  77.190002   \n",
       "2015-01-06             506.640015  499.212799  76.150002   \n",
       "2015-01-07             505.149994  498.357513  76.150002   \n",
       "2015-01-08             506.910004  499.928864  78.180000   \n",
       "\n",
       "Sector     Consumer Discretionary                        Financials  \\\n",
       "Asset                     asset_1     asset_2    asset_3    asset_1   \n",
       "Date                                                                  \n",
       "2015-01-02             308.519989  103.430000  93.260002  62.490002   \n",
       "2015-01-05             302.190002  101.260002  92.230003  60.549999   \n",
       "2015-01-06             295.290009  100.949997  92.400002  58.980000   \n",
       "2015-01-07             298.420013  104.410004  94.010002  59.070000   \n",
       "2015-01-08             300.459991  106.720001  94.360001  60.389999   \n",
       "\n",
       "Sector                           Information Technology                        \n",
       "Asset         asset_2    asset_3                asset_1    asset_2    asset_3  \n",
       "Date                                                                           \n",
       "2015-01-02  17.900000  54.700001             109.330002  46.759998  66.254997  \n",
       "2015-01-05  17.379999  53.200001             106.250000  46.330002  64.792503  \n",
       "2015-01-06  16.860001  52.090000             106.260002  45.650002  64.375000  \n",
       "2015-01-07  16.940001  52.400002             107.750000  46.230000  65.237503  \n",
       "2015-01-08  17.290001  53.560001             111.889999  47.590000  66.112503  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sector in stocks:\n",
    "    for i, stock in enumerate(stocks[sector]):\n",
    "        stock_name = 'asset_' + str(i+1)\n",
    "        df.loc[:,(sector, stock_name)] = snp[stock]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Represent DataFrame as one column Multi-index data**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Sector                  Asset  \n",
       "2015-01-02  Communication Services  asset_1    529.549988\n",
       "                                    asset_2    521.937744\n",
       "                                    asset_3     78.449997\n",
       "            Consumer Discretionary  asset_1    308.519989\n",
       "                                    asset_2    103.430000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tensor = df.stack([0, 1])\n",
    "df_tensor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN -- for visualization and help\n",
    "# df_tensor.reorder_levels([1,2,0])[:30]\n",
    "# df_tensor.reorder_levels([1,2,0])['Information Technology']['asset_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Tensorize the data**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hottbox.core import Tensor\n",
    "# from hottbox.pdtools import pd_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = pd_to_tensor(df_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Helper Fuctions**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluates the confidence in the predicted downturns\n",
    "def downturn_confidence(actual, predicted):\n",
    "    n = 0\n",
    "    x = 0\n",
    "    for i in range(len(actual)):\n",
    "        if predicted[i] == 0:\n",
    "            n += 1\n",
    "            if predicted[i] == actual[i]:\n",
    "                x += 1\n",
    "    \n",
    "    return None if n == 0 else (n, x, x/n)\n",
    "\n",
    "\n",
    "# Helper function to display scores of multiclass classification\n",
    "def print_scores(scores):\n",
    "    result = []\n",
    "    for score in scores:\n",
    "        s = \"{:.2f}%\".format(score * 100)\n",
    "        result.append(s)\n",
    "        \n",
    "    print('[' + \", \".join(result) + ']')\n",
    "    \n",
    "def print_1_percentage(y):\n",
    "    percentages = sum(y == 1.)/len(y)\n",
    "    percentages = list(percentages) if n_classes > 1 else [percentages]\n",
    "\n",
    "    print_scores(percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Create training samples and labels, i.e. training data, $\\mathcal{D}$**\n",
    "------------------------------------\n",
    "Create the dataset with tensor samples and vector labels: \n",
    "- Samples are stock prices of each stock windowed at a particular window length up to the prediction date, $t$. Samples are represented as third order tensors, with modes being `['Sector', 'Asset', 'Date']`. The samples are of size (#Sectors, #Assets in each sector, Window length). \n",
    "- Labels are stock prices of each stock at the prediction date, $t$. They are represented as vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hottbox.core import Tensor\n",
    "from hottbox.pdtools import pd_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 66 # window length\n",
    "future_days = 22 # number of days to the future we are predicting the price at\n",
    "future_days -= 1 # for indexing\n",
    "\n",
    "## Creating Samples\n",
    "X = []\n",
    "for i in range(w, len(snp.index) - future_days):\n",
    "    df_t = df.iloc[i-w:i]\n",
    "    df_t = df_t.stack([0, 1])\n",
    "    X_t = pd_to_tensor(df_t)\n",
    "    \n",
    "    X.append(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates are the same, we are good to go!\n"
     ]
    }
   ],
   "source": [
    "if sum(snp.index != snp500.index) == 0:\n",
    "    print('Dates are the same, we are good to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "## Labels are all assets' price movements\n",
    "for i in range(w+future_days, len(snp.index)):\n",
    "    price_old = np.array(df.iloc[i-future_days-1])\n",
    "    price_future = np.array(df.iloc[i])\n",
    "    diff = price_future - price_old\n",
    "    y_t = np.sign(np.sign(diff) + 1.)\n",
    "    \n",
    "    y.append(y_t)\n",
    "\n",
    "\n",
    "## Labels are the S&P 500 Index movements\n",
    "# for i in range(w, len(snp500.index)):\n",
    "#     price_old = snp500[i-1]\n",
    "#     price_now = snp500[i]\n",
    "#     diff = price_now - price_old\n",
    "#     y_t = str(np.sign(diff))\n",
    "    \n",
    "#     y.append(y_t)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Tensor Ensemble Learning**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hottbox.core import Tensor, TensorTKD\n",
    "from hottbox.algorithms.decomposition import HOSVD, HOOI\n",
    "# from hottbox.utils.generation import residual_tensor\n",
    "from hottbox.algorithms.classification import TelVI\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRTEL:\n",
    "    def __init__(self, base_clfs, n_classes=1, probability=False, verbose=False):\n",
    "        self.probability = probability\n",
    "        self.verbose = verbose\n",
    "        self.n_classes = n_classes\n",
    "        self.models = [TelVI(base_clf=base_clfs[i], probability=self.probability, verbose=self.verbose) for i in range(self.n_classes)]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if n_classes == 1:\n",
    "            self.models[0].fit(X, y)\n",
    "        elif n_classes > 1:\n",
    "            for i in range(self.n_classes):\n",
    "                print(i, end=\" - \")\n",
    "                self.models[i].fit(X, y[:,i])\n",
    "            print()\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        if n_classes == 1:\n",
    "            return self.models[0].score(X, y)\n",
    "        elif n_classes > 1:\n",
    "            scores = []\n",
    "            for i in range(self.n_classes):\n",
    "                scores.append(self.models[i].score(X, y[:, i]))\n",
    "            return scores\n",
    "    \n",
    "    def grid_search(self, X, y, search_params):\n",
    "        if n_classes == 1:\n",
    "            self.models[0].grid_search(X, y, search_params)\n",
    "        elif n_classes > 1:\n",
    "            for i in range(self.n_classes):\n",
    "                print(i, end=\" - \")\n",
    "                self.models[i].grid_search(X, y[:,i], search_params)\n",
    "            print()\n",
    "                \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(self.n_classes):\n",
    "            predictions.append(self.models[i].predict(X))\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - \n",
      "\n",
      "Classification accuracy (Train):\n",
      "[58.37%, 58.21%, 63.58%, 72.85%, 60.98%, 68.29%, 62.44%, 59.02%, 53.33%, 60.81%, 68.29%, 70.08%]\n",
      "\n",
      "Classification accuracy (Test):\n",
      "[63.49%, 62.83%, 63.82%, 75.66%, 60.53%, 62.17%, 62.50%, 60.20%, 54.93%, 56.91%, 71.05%, 67.11%]\n",
      "\n",
      "Percentage of 1s (Test):\n",
      "[63.16%, 62.17%, 63.82%, 75.66%, 60.53%, 62.17%, 62.50%, 59.87%, 54.93%, 56.25%, 71.05%, 67.11%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Represent each sample in Tucker form and store it in a list\n",
    "algo = HOSVD()\n",
    "rank = (6,2,2)\n",
    "X_tk = [algo.decompose(sample, rank=rank) for sample in X]\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tk, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# test_size = 0.33\n",
    "# k = int(len(X_tk) * (1. - 0.33))\n",
    "\n",
    "# X_train, X_test = X_tk[:k], X_tk[k:]\n",
    "# y_train, y_test = y[:k], y[k:]\n",
    "\n",
    "\n",
    "# Initialise classifier\n",
    "R = np.sum(rank) # number of base classifiers required per class\n",
    "n_classes = 1 if y.ndim == 1 else y.shape[1]\n",
    "\n",
    "base_clfs = []\n",
    "for _ in range(n_classes):\n",
    "    base_clfs.append([SVC(gamma='auto') for _ in range(R)])\n",
    "\n",
    "grtel = GRTEL(base_clfs=base_clfs,\n",
    "              n_classes=n_classes,\n",
    "              probability=True,\n",
    "              verbose=False)\n",
    "\n",
    "\n",
    "# Train classifer\n",
    "grtel.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Scores\n",
    "score = grtel.score(X_train, y_train)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"\\nClassification accuracy (Train):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "score = grtel.score(X_test, y_test)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Test):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "print(\"Percentage of 1s (Test):\")\n",
    "print_1_percentage(y_test); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPerforming grid search for each base classifer\n",
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - \n",
      "\tTrain base classifiers with optimal hyperparameters\n",
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - \n",
      "\n",
      "Classification accuracy (Train):\n",
      "[93.17%, 100.00%, 98.54%, 79.02%, 99.84%, 100.00%, 92.52%, 100.00%, 100.00%, 100.00%, 90.89%, 100.00%]\n",
      "\n",
      "Classification accuracy (Test):\n",
      "[70.39%, 74.01%, 74.67%, 77.63%, 69.08%, 63.16%, 69.74%, 76.32%, 84.54%, 73.36%, 74.01%, 68.09%]\n",
      "\n",
      "Percentage of 1s (Test):\n",
      "[63.16%, 62.17%, 63.82%, 75.66%, 60.53%, 62.17%, 62.50%, 59.87%, 54.93%, 56.25%, 71.05%, 67.11%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_params = [dict(gamma=[0.001, 0.01, 1, 10], C=[0.1, 1, 10, 100]) for _ in range(R)]\n",
    "\n",
    "print(\"\\tPerforming grid search for each base classifer\")\n",
    "grtel.grid_search(X_train, y_train, search_params)\n",
    "\n",
    "print(\"\\tTrain base classifiers with optimal hyperparameters\")\n",
    "grtel.fit(X_train, y_train); print()\n",
    "\n",
    "score = grtel.score(X_train, y_train)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Train):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "score = grtel.score(X_test, y_test)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Test):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "print(\"Percentage of 1s (Test):\")\n",
    "print_1_percentage(y_test); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38, 30, 0.7894736842105263),\n",
       " (52, 43, 0.8269230769230769),\n",
       " (41, 36, 0.8780487804878049),\n",
       " (4, 4, 1.0),\n",
       " (28, 27, 0.9642857142857143),\n",
       " (1, 1, 1.0),\n",
       " (28, 26, 0.9285714285714286),\n",
       " (51, 44, 0.8627450980392157),\n",
       " (81, 72, 0.8888888888888888),\n",
       " (71, 62, 0.8732394366197183),\n",
       " (19, 19, 1.0),\n",
       " (1, 1, 1.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(12):\n",
    "    results.append(downturn_confidence(y_test[:,i], grtel.models[i].predict(X_test)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zeros = pd.DataFrame([grtel.models[i].predict(X_test) for i in range(n_classes)]).T\n",
    "\n",
    "# print(len(df_zeros[df_zeros[0] == 0]))\n",
    "# df_zeros[df_zeros[0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(173, 171, 0.9884393063583815),\n",
       " (232, 229, 0.9870689655172413),\n",
       " (183, 182, 0.994535519125683),\n",
       " (30, 30, 1.0),\n",
       " (185, 185, 1.0),\n",
       " (186, 186, 1.0),\n",
       " (150, 149, 0.9933333333333333),\n",
       " (161, 161, 1.0),\n",
       " (284, 284, 1.0),\n",
       " (251, 249, 0.9920318725099602),\n",
       " (105, 105, 1.0),\n",
       " (184, 184, 1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(12):\n",
    "    results.append(downturn_confidence(y_train[:,i], grtel.models[i].predict(X_train)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zeros = pd.DataFrame([grtel.models[i].predict(X_train) for i in range(n_classes)]).T\n",
    "\n",
    "# print(len(df_zeros[df_zeros[0] == 0]))\n",
    "# df_zeros[df_zeros[0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
