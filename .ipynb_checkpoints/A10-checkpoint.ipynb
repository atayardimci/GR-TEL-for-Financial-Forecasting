{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Set paths\n",
    "fig_path = './figures/'\n",
    "data_path = './data/'\n",
    "yf_path = './data/yf_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Get the companies**\n",
    "------------------------------------\n",
    "\n",
    "Choose 4 sectors (`Communication Services, Consumer Discretionary, Financials, Information Technology`) and select the 3 companies with largest mcaps within each sector. Chosen assets for analysis is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "mydateparser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "snp = pd.read_csv(data_path+\"snp_allstocks_2015_2019.csv\", index_col='Date', parse_dates=True, date_parser=mydateparser)\n",
    "info = pd.read_csv(data_path+'snp_info.csv', index_col=0)\n",
    "\n",
    "\n",
    "# https://www.slickcharts.com/sp500\n",
    "# https://datahub.io/core/s-and-p-500-companies-financials\n",
    "detailed_info = pd.read_csv(data_path+'constituents-financials.csv', index_col=0)\n",
    "stocks_sorted = detailed_info.sort_values('Market Cap', ascending=False)['Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_by_sector = {sector: [] for sector in info['GICS Sector'].unique()}\n",
    "\n",
    "for stock in stocks_sorted.index[:160]:\n",
    "    if stock in ['PCLN', 'TWX', 'AET', 'MON', 'PX', 'ESRX']:\n",
    "        continue\n",
    "    stock = 'BRK-B' if stock == 'BRK.B' else stock\n",
    "    \n",
    "    sector = info.set_index('Symbol').loc[stock]['GICS Sector']\n",
    "    stocks_by_sector[sector].append(stock)\n",
    "# stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Communication Services': ['GOOGL', 'GOOG', 'FB'],\n",
       " 'Consumer Discretionary': ['AMZN', 'HD', 'MCD'],\n",
       " 'Financials': ['JPM', 'BAC', 'WFC'],\n",
       " 'Information Technology': ['AAPL', 'MSFT', 'V']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select top three stocks (by market cap) within each GICS Sector\n",
    "stocks = {}\n",
    "for sector in stocks_by_sector:\n",
    "    stocks[sector] = stocks_by_sector[sector][:3]\n",
    "\n",
    "# use a subset of stocks instead for easy understanding\n",
    "# order sectors alphabetically\n",
    "tmp = {}\n",
    "tmp['Communication Services'] = stocks['Communication Services']\n",
    "tmp['Consumer Discretionary'] = stocks['Consumer Discretionary']\n",
    "tmp['Financials'] = stocks['Financials']\n",
    "tmp['Information Technology'] = stocks['Information Technology']\n",
    "\n",
    "stocks = tmp\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Get the data and the indicators**\n",
    "------------------------------------\n",
    "We collect the stock data from yfinance for between dates `'2015-01-02'-'2019-01-01'` (4 years) and calculate certain indicators helpful for analysis, which are:\n",
    "- Relative Strength Index (RSI)\n",
    "- Stochastic Oscillator\n",
    "- Williams %R\n",
    "- Moving Average Convergence Divergnece (MACD)\n",
    "- Price Rate Of Change\n",
    "- On Balance Volume\n",
    "\n",
    "After calculating these indicators for each day, we add them to the dataframe of the stock as new columns. We select the columns `['Close', 'RSI', 'k_percent', 'r_percent', 'MACD', 'MACD_EMA9', 'Price Rate Of Change', 'On Balance Volume']` at the end to obtain a new dataframe representing the stock.\n",
    "\n",
    "We do this for each of the stocks we have selected and concatenate the individual dataframes to obtain a a resulting dataframe of shape `(T, NxM)`, where `T` is the number of time steps, `N` the number of assets, `M` the number of indicators for each asset.\n",
    "\n",
    "We also standardize the names of individual assets (e.g. `asset_1`) for tensorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate n-day RSI\n",
    "def get_RSI(data, n=14):\n",
    "    # First make a copy of the data frame twice\n",
    "    up_df, down_df = data['change_in_price'].copy(), data['change_in_price'].copy()\n",
    "    \n",
    "    # For up days, if the change is less than 0 set to 0.\n",
    "    up_df[up_df < 0] = 0\n",
    "    # For down days, if the change is greater than 0 set to 0.\n",
    "    down_df[down_df > 0] = 0\n",
    "    # We need change_in_price to be absolute.\n",
    "    down_df = down_df.abs()\n",
    "    \n",
    "    # Calculate the EWMA (Exponential Weighted Moving Average)\n",
    "    ewma_up = up_df.ewm(span=n).mean()\n",
    "    ewma_down = down_df.ewm(span=n).mean()\n",
    "    \n",
    "    # Calculate the Relative Strength\n",
    "    relative_strength = ewma_up / ewma_down\n",
    "\n",
    "    # Calculate the Relative Strength Index\n",
    "    relative_strength_index = 100.0 - (100.0 / (1.0 + relative_strength))\n",
    "    \n",
    "    return relative_strength_index\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the n-day Stochastic Oscillator\n",
    "def get_Stochastic_Oscillator(data, n=14):\n",
    "    # Make a copy of the high and low column.\n",
    "    low, high = data['Low'].copy(), data['High'].copy()\n",
    "    \n",
    "    # Calculate rolling min and max.\n",
    "    low = low.rolling(window=n).min()\n",
    "    high = high.rolling(window=n).max()\n",
    "    \n",
    "    # Calculate the Stochastic Oscillator.\n",
    "    k_percent = 100 * ((data['Close'] - low) / (high - low))\n",
    "    \n",
    "    return k_percent\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the Williams %R\n",
    "def get_Williams(data, n=14):\n",
    "    # Make a copy of the high and low column.\n",
    "    low, high = data['Low'].copy(), data['High'].copy()\n",
    "    \n",
    "    # Calculate rolling min and max.\n",
    "    low = low.rolling(window=n).min()\n",
    "    high = high.rolling(window=n).max()\n",
    "    \n",
    "    # Calculate William %R indicator.\n",
    "    r_percent = ((high - data['Close']) / (high - low)) * -100\n",
    "    \n",
    "    return r_percent\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the MACD\n",
    "def get_MACD(data):\n",
    "    ema_26 = data['Close'].ewm(span=26).mean()\n",
    "    ema_12 = data['Close'].ewm(span=12).mean()\n",
    "\n",
    "    macd = ema_12 - ema_26\n",
    "\n",
    "    # Calculate the EMA of MACD\n",
    "    ema_9_macd = macd.ewm(span=9).mean()\n",
    "    \n",
    "    return macd, ema_9_macd\n",
    "    \n",
    "\n",
    "    \n",
    "# Calculate On Balance Volume\n",
    "def get_OBV(data):\n",
    "    volumes = data['Volume']\n",
    "    changes = data['change_in_price']\n",
    "\n",
    "    prev_obv = 0\n",
    "    obv_values = []\n",
    "    for change, volume in zip(changes, volumes):\n",
    "        if change > 0:\n",
    "            current_obv = prev_obv + volume\n",
    "        elif change < 0:\n",
    "            current_obv = prev_obv - volume\n",
    "        else:\n",
    "            current_obv = prev_obv\n",
    "\n",
    "        obv_values.append(current_obv)\n",
    "        prev_obv = current_obv\n",
    "\n",
    "    return pd.Series(obv_values, index=data.index)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `labels` are set according to the price change $n$ days-out (set to be 9 below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "for sector in stocks:\n",
    "    for i, stock in enumerate(stocks[sector]):\n",
    "        \n",
    "        stock_name = 'asset_' + str(i+1)\n",
    "        \n",
    "        # get the original data\n",
    "        data = pd.read_csv(yf_path+stock+\".csv\", index_col='Date', parse_dates=True, date_parser=mydateparser)\n",
    "\n",
    "        # calculate change in price\n",
    "        data['change_in_price'] = data['Close'].diff()\n",
    "\n",
    "        # calculate indicators\n",
    "        data['RSI'] = get_RSI(data)\n",
    "        data['k_percent'] = get_Stochastic_Oscillator(data)\n",
    "        data['r_percent'] = get_Williams(data)\n",
    "\n",
    "        # Calculate the MACD\n",
    "        macd, ema_9_macd = get_MACD(data)\n",
    "        data['MACD'] = macd\n",
    "        data['MACD_EMA9'] = ema_9_macd\n",
    "\n",
    "        # Calculate the 9-day Price Rate of Change\n",
    "        data['Price Rate Of Change'] = data['Close'].pct_change(periods=9)\n",
    "\n",
    "        # Calculate On Balance Volume\n",
    "        data['On Balance Volume'] = get_OBV(data)\n",
    "\n",
    "        # Create the predicition column (To keep this as a binary classifier we'll consider flat days as up days)\n",
    "        days_out = 9\n",
    "        data['Prediction'] = np.sign(np.sign(data['Close'].shift(-days_out) - data['Close']) + 1.)\n",
    "\n",
    "        # Drop rows with NaN.\n",
    "        data = data.dropna()\n",
    "\n",
    "        X_i = data[['Close', 'RSI', 'k_percent', 'r_percent', 'MACD', 'MACD_EMA9', 'Price Rate Of Change', 'On Balance Volume']].copy()\n",
    "        X_i.columns = [[sector]*len(X_i.columns), [stock_name]*len(X_i.columns), X_i.columns]\n",
    "        \n",
    "        y_i = data['Prediction'].copy()\n",
    "        y_i.name = stock\n",
    "        \n",
    "        samples.append(X_i)\n",
    "        labels.append(y_i)\n",
    "\n",
    "        \n",
    "samples = pd.concat(samples, axis=1)\n",
    "samples.columns.names = ['Sector', 'Asset', 'Metrics']\n",
    "\n",
    "labels = pd.concat(labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Communication Services</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Information Technology</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asset</th>\n",
       "      <th colspan=\"8\" halign=\"left\">asset_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asset_2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">asset_2</th>\n",
       "      <th colspan=\"8\" halign=\"left\">asset_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th>Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>k_percent</th>\n",
       "      <th>r_percent</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_EMA9</th>\n",
       "      <th>Price Rate Of Change</th>\n",
       "      <th>On Balance Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>...</th>\n",
       "      <th>Price Rate Of Change</th>\n",
       "      <th>On Balance Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>RSI</th>\n",
       "      <th>k_percent</th>\n",
       "      <th>r_percent</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_EMA9</th>\n",
       "      <th>Price Rate Of Change</th>\n",
       "      <th>On Balance Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-22</th>\n",
       "      <td>537.299988</td>\n",
       "      <td>78.297375</td>\n",
       "      <td>96.786901</td>\n",
       "      <td>-3.213099</td>\n",
       "      <td>1.956715</td>\n",
       "      <td>-0.117862</td>\n",
       "      <td>0.059951</td>\n",
       "      <td>-33200</td>\n",
       "      <td>532.926819</td>\n",
       "      <td>79.627212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009666</td>\n",
       "      <td>-94025500</td>\n",
       "      <td>64.400002</td>\n",
       "      <td>44.509507</td>\n",
       "      <td>40.000040</td>\n",
       "      <td>-59.999960</td>\n",
       "      <td>-0.143929</td>\n",
       "      <td>-0.121585</td>\n",
       "      <td>-0.025903</td>\n",
       "      <td>13929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-23</th>\n",
       "      <td>541.950012</td>\n",
       "      <td>80.642355</td>\n",
       "      <td>93.651444</td>\n",
       "      <td>-6.348556</td>\n",
       "      <td>3.404653</td>\n",
       "      <td>0.612332</td>\n",
       "      <td>0.082341</td>\n",
       "      <td>2265100</td>\n",
       "      <td>538.471619</td>\n",
       "      <td>82.229428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-67813900</td>\n",
       "      <td>64.572502</td>\n",
       "      <td>47.916069</td>\n",
       "      <td>47.449404</td>\n",
       "      <td>-52.550596</td>\n",
       "      <td>-0.118848</td>\n",
       "      <td>-0.121018</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>20096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-26</th>\n",
       "      <td>536.719971</td>\n",
       "      <td>70.724965</td>\n",
       "      <td>84.055032</td>\n",
       "      <td>-15.944968</td>\n",
       "      <td>4.143347</td>\n",
       "      <td>1.338989</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>718500</td>\n",
       "      <td>533.744629</td>\n",
       "      <td>73.051049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>-110339400</td>\n",
       "      <td>64.132500</td>\n",
       "      <td>40.583452</td>\n",
       "      <td>35.150242</td>\n",
       "      <td>-64.849758</td>\n",
       "      <td>-0.125008</td>\n",
       "      <td>-0.121839</td>\n",
       "      <td>-0.013422</td>\n",
       "      <td>11544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-27</th>\n",
       "      <td>521.190002</td>\n",
       "      <td>49.758853</td>\n",
       "      <td>55.559662</td>\n",
       "      <td>-44.440338</td>\n",
       "      <td>3.694220</td>\n",
       "      <td>1.820886</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>-1238900</td>\n",
       "      <td>517.210022</td>\n",
       "      <td>50.362629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079810</td>\n",
       "      <td>-279503400</td>\n",
       "      <td>62.747501</td>\n",
       "      <td>26.085235</td>\n",
       "      <td>13.987256</td>\n",
       "      <td>-86.012744</td>\n",
       "      <td>-0.213865</td>\n",
       "      <td>-0.140668</td>\n",
       "      <td>-0.037541</td>\n",
       "      <td>516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-28</th>\n",
       "      <td>512.429993</td>\n",
       "      <td>41.711036</td>\n",
       "      <td>39.486240</td>\n",
       "      <td>-60.513760</td>\n",
       "      <td>2.752592</td>\n",
       "      <td>2.010646</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>-3030000</td>\n",
       "      <td>508.603638</td>\n",
       "      <td>42.445246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103786</td>\n",
       "      <td>-364010500</td>\n",
       "      <td>61.590000</td>\n",
       "      <td>19.401479</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>-99.692478</td>\n",
       "      <td>-0.352269</td>\n",
       "      <td>-0.183765</td>\n",
       "      <td>-0.035999</td>\n",
       "      <td>-10914400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sector     Communication Services                                             \\\n",
       "Asset                     asset_1                                              \n",
       "Metrics                     Close        RSI  k_percent  r_percent      MACD   \n",
       "Date                                                                           \n",
       "2015-01-22             537.299988  78.297375  96.786901  -3.213099  1.956715   \n",
       "2015-01-23             541.950012  80.642355  93.651444  -6.348556  3.404653   \n",
       "2015-01-26             536.719971  70.724965  84.055032 -15.944968  4.143347   \n",
       "2015-01-27             521.190002  49.758853  55.559662 -44.440338  3.694220   \n",
       "2015-01-28             512.429993  41.711036  39.486240 -60.513760  2.752592   \n",
       "\n",
       "Sector                                                                   \\\n",
       "Asset                                                           asset_2   \n",
       "Metrics    MACD_EMA9 Price Rate Of Change On Balance Volume       Close   \n",
       "Date                                                                      \n",
       "2015-01-22 -0.117862             0.059951            -33200  532.926819   \n",
       "2015-01-23  0.612332             0.082341           2265100  538.471619   \n",
       "2015-01-26  1.338989             0.079789            718500  533.744629   \n",
       "2015-01-27  1.820886             0.038641          -1238900  517.210022   \n",
       "2015-01-28  2.010646             0.012848          -3030000  508.603638   \n",
       "\n",
       "Sector                       ...        Information Technology  \\\n",
       "Asset                        ...                       asset_2   \n",
       "Metrics           RSI        ...          Price Rate Of Change   \n",
       "Date                         ...                                 \n",
       "2015-01-22  79.627212        ...                     -0.009666   \n",
       "2015-01-23  82.229428        ...                     -0.000212   \n",
       "2015-01-26  73.051049        ...                      0.008798   \n",
       "2015-01-27  50.362629        ...                     -0.079810   \n",
       "2015-01-28  42.445246        ...                     -0.103786   \n",
       "\n",
       "Sector                                                                    \\\n",
       "Asset                           asset_3                                    \n",
       "Metrics    On Balance Volume      Close        RSI  k_percent  r_percent   \n",
       "Date                                                                       \n",
       "2015-01-22         -94025500  64.400002  44.509507  40.000040 -59.999960   \n",
       "2015-01-23         -67813900  64.572502  47.916069  47.449404 -52.550596   \n",
       "2015-01-26        -110339400  64.132500  40.583452  35.150242 -64.849758   \n",
       "2015-01-27        -279503400  62.747501  26.085235  13.987256 -86.012744   \n",
       "2015-01-28        -364010500  61.590000  19.401479   0.307522 -99.692478   \n",
       "\n",
       "Sector                                                                 \n",
       "Asset                                                                  \n",
       "Metrics         MACD MACD_EMA9 Price Rate Of Change On Balance Volume  \n",
       "Date                                                                   \n",
       "2015-01-22 -0.143929 -0.121585            -0.025903          13929600  \n",
       "2015-01-23 -0.118848 -0.121018            -0.008598          20096400  \n",
       "2015-01-26 -0.125008 -0.121839            -0.013422          11544000  \n",
       "2015-01-27 -0.213865 -0.140668            -0.037541            516400  \n",
       "2015-01-28 -0.352269 -0.183765            -0.035999         -10914400  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>FB</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>HD</th>\n",
       "      <th>MCD</th>\n",
       "      <th>JPM</th>\n",
       "      <th>BAC</th>\n",
       "      <th>WFC</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOOGL  GOOG   FB  AMZN   HD  MCD  JPM  BAC  WFC  AAPL  MSFT    V\n",
       "Date                                                                        \n",
       "2015-01-22    0.0   0.0  0.0   1.0  1.0  1.0  0.0  0.0  0.0   1.0   0.0  1.0\n",
       "2015-01-23    0.0   0.0  0.0   1.0  1.0  1.0  1.0  1.0  1.0   1.0   0.0  1.0\n",
       "2015-01-26    0.0   0.0  0.0   1.0  1.0  1.0  1.0  1.0  1.0   1.0   0.0  1.0\n",
       "2015-01-27    1.0   1.0  0.0   1.0  1.0  1.0  1.0  1.0  1.0   1.0   0.0  1.0\n",
       "2015-01-28    1.0   1.0  0.0   1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0  1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**GLTD**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "from hottbox.core import Tensor, TensorTKD\n",
    "from hottbox.algorithms.decomposition import HOSVD, HOOI\n",
    "from hottbox.utils.generation import residual_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented for third order tensor decomposition\n",
    "# Last mode should be the regularized mode\n",
    "class GLTD:\n",
    "    def __init__(self, max_iter=50, epsilon=1e-2, tol=1e-4, verbose=False):\n",
    "        self.max_iter = max_iter\n",
    "        self.epsilon = epsilon\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "        \n",
    "    def decompose(self, tensor, rank):\n",
    "        \n",
    "        if not isinstance(tensor, Tensor):\n",
    "            raise TypeError(\"Parameter `tensor` should be an object of `Tensor` class!\")\n",
    "        if not isinstance(rank, tuple):\n",
    "            raise TypeError(\"Parameter `rank` should be passed as a tuple!\")\n",
    "        if tensor.order != len(rank):\n",
    "            raise ValueError(\"Parameter `rank` should be a tuple of same length as the order of a tensor:\\n\"\n",
    "                             \"{} != {} (tensor.order != len(rank))\".format(tensor.order, len(rank)))\n",
    "        \n",
    "        converged = False\n",
    "        cost = []\n",
    "        tensor_tkd = None\n",
    "        fmat_gltd = self._init_fmat(tensor, rank)\n",
    "        norm = tensor.frob_norm\n",
    "        for n_iter in range(self.max_iter):\n",
    "\n",
    "            # Update factor matrices\n",
    "            # step 1\n",
    "            V, W = fmat_gltd[1], fmat_gltd[2]\n",
    "            VVT = np.dot(V, V.T)\n",
    "            WWT = np.dot(W, W.T)\n",
    "\n",
    "            A = tensor.mode_n_product(VVT, mode=1, inplace=False)\n",
    "            B = tensor.mode_n_product(WWT, mode=2, inplace=False)\n",
    "\n",
    "            n = tensor.shape[0]\n",
    "            F = np.zeros((n,n))\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    F[i,j] = np.trace(np.dot(A[i,:,:].T, B[j,:,:]))\n",
    "\n",
    "            U, _, _ = scipy.linalg.svd(F)\n",
    "            U = U[:,:rank[0]]\n",
    "            fmat_gltd[0] = U\n",
    "\n",
    "            # step 2\n",
    "            U, W = fmat_gltd[0], fmat_gltd[2]\n",
    "            UUT = np.dot(U, U.T)\n",
    "            WWT = np.dot(W, W.T)\n",
    "\n",
    "            A = tensor.mode_n_product(UUT, mode=0, inplace=False)\n",
    "            B = tensor.mode_n_product(WWT, mode=2, inplace=False)\n",
    "\n",
    "            n = tensor.shape[1]\n",
    "            G = np.zeros((n,n))\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    G[i,j] = np.trace(np.dot(A[:,i,:].T, B[:,j,:]))\n",
    "\n",
    "            V, _, _ = scipy.linalg.svd(G)\n",
    "            V = V[:,:rank[1]]\n",
    "            fmat_gltd[1] = V\n",
    "\n",
    "            # step 3\n",
    "            U, V = fmat_gltd[0], fmat_gltd[1]\n",
    "            UUT = np.dot(U, U.T)\n",
    "            VVT = np.dot(V, V.T)\n",
    "\n",
    "            A = tensor.mode_n_product(UUT, mode=0, inplace=False)\n",
    "            B = tensor.mode_n_product(VVT, mode=1, inplace=False)\n",
    "\n",
    "            n = tensor.shape[2]\n",
    "            H = np.zeros((n,n))\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    H[i,j] = np.trace(np.dot(A[:,:,i].T, B[:,:,j]))\n",
    "\n",
    "            # add regularization here\n",
    "            W, _, _ = scipy.linalg.svd(H)\n",
    "            W = W[:,:rank[2]]\n",
    "            fmat_gltd[2] = W\n",
    "\n",
    "\n",
    "            # Update core\n",
    "            core = tensor.copy()\n",
    "            for mode, fmat in enumerate(fmat_gltd):\n",
    "                core.mode_n_product(fmat.T, mode=mode)\n",
    "\n",
    "\n",
    "            # Update cost\n",
    "            tensor_tkd = TensorTKD(fmat=fmat_gltd, core_values=core.data)\n",
    "            residual = residual_tensor(tensor, tensor_tkd)\n",
    "            cost.append(abs(residual.frob_norm / norm))\n",
    "\n",
    "            # Check termination conditions\n",
    "            if cost[-1] <= self.epsilon:\n",
    "                if self.verbose:\n",
    "                    print('Relative error of approximation has reached the acceptable level: {}'.format(cost[-1]))\n",
    "                break\n",
    "            if len(cost) >= 2 and abs(cost[-2] - cost[-1]) <= self.tol:\n",
    "                converged = True\n",
    "                if self.verbose:\n",
    "                    print('Converged in {} iteration(s)'.format(len(cost)))\n",
    "                break\n",
    "                \n",
    "        if not converged and cost[-1] > self.epsilon:\n",
    "            print('Maximum number of iterations ({}) has been reached. '\n",
    "                  'Variation = {}'.format(self.max_iter, abs(cost[-2] - cost[-1])))\n",
    "            \n",
    "        return tensor_tkd\n",
    "    \n",
    "\n",
    "    \n",
    "    def _init_fmat(self, tensor, rank):\n",
    "        \"\"\" Initialisation of factor matrices\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor : Tensor\n",
    "            Multidimensional data to be decomposed\n",
    "        rank : tuple\n",
    "            Desired multilinear rank for the given `tensor`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fmat : list[np.ndarray]\n",
    "            List of factor matrices\n",
    "        \"\"\"\n",
    "#         hosvd = HOSVD()\n",
    "#         tensor_hosvd = hosvd.decompose(tensor, rank)\n",
    "#         fmat = tensor_hosvd.fmat\n",
    "\n",
    "        #init fmat as the identity matrix\n",
    "        fmat = []\n",
    "        fmat.append(np.identity(tensor.shape[0])[:,:rank[0]])\n",
    "        fmat.append(np.identity(tensor.shape[1])[:,:rank[1]])\n",
    "        fmat.append(np.identity(tensor.shape[2])[:,:rank[2]])\n",
    "\n",
    "        return fmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "**Tensor Ensemble Learning**\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluates the confidence in the predicted downturns\n",
    "def downturn_confidence(actual, predicted):\n",
    "    n = 0\n",
    "    x = 0\n",
    "    for i in range(len(actual)):\n",
    "        if predicted[i] == 0:\n",
    "            n += 1\n",
    "            if predicted[i] == actual[i]:\n",
    "                x += 1\n",
    "    \n",
    "    return None if n == 0 else (n, x, x/n)\n",
    "\n",
    "# Helper function to display scores of multiclass classification\n",
    "def print_scores(scores):\n",
    "    result = []\n",
    "    for score in scores:\n",
    "        s = \"{:.2f}%\".format(score * 100)\n",
    "        result.append(s)\n",
    "        \n",
    "    print('[' + \", \".join(result) + ']')\n",
    "    \n",
    "def print_1_percentage(y):\n",
    "    percentages = sum(y == 1.)/len(y)\n",
    "    percentages = list(percentages) if n_classes > 1 else [percentages]\n",
    "\n",
    "    print_scores(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hottbox.core import Tensor, TensorTKD\n",
    "from hottbox.pdtools import pd_to_tensor\n",
    "from hottbox.algorithms.decomposition import HOSVD, HOOI\n",
    "# from hottbox.utils.generation import residual_tensor\n",
    "from hottbox.algorithms.classification import TelVI\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tensor is of order 3 and consists of 96 elements.\n",
      "Sizes and names of its modes are (8, 3, 4) and ['Metrics', 'Asset', 'Sector'] respectively. \n",
      "\n",
      " [0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(len(samples)):\n",
    "    X_t = samples.iloc[i].reorder_levels(['Metrics', 'Asset', 'Sector']) #Make 'Sector' the third mode of the tensor\n",
    "    X.append(pd_to_tensor(X_t))\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "print(X[0], '\\n\\n', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRTEL:\n",
    "    def __init__(self, base_clfs, n_classes=1, probability=False, verbose=False):\n",
    "        self.probability = probability\n",
    "        self.verbose = verbose\n",
    "        self.n_classes = n_classes\n",
    "        self.models = [TelVI(base_clf=base_clfs[i], probability=self.probability, verbose=self.verbose) for i in range(self.n_classes)]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if n_classes == 1:\n",
    "            self.models[0].fit(X, y)\n",
    "        elif n_classes > 1:\n",
    "            for i in range(self.n_classes):\n",
    "                print(i, end=\" - \")\n",
    "                self.models[i].fit(X, y[:,i])\n",
    "            print()\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        if n_classes == 1:\n",
    "            return self.models[0].score(X, y)\n",
    "        elif n_classes > 1:\n",
    "            scores = []\n",
    "            for i in range(self.n_classes):\n",
    "                scores.append(self.models[i].score(X, y[:, i]))\n",
    "            return scores\n",
    "    \n",
    "    def grid_search(self, X, y, search_params):\n",
    "        if n_classes == 1:\n",
    "            self.models[0].grid_search(X, y, search_params)\n",
    "        elif n_classes > 1:\n",
    "            for i in range(self.n_classes):\n",
    "                print(i, end=\" - \")\n",
    "                self.models[i].grid_search(X, y[:,i], search_params)\n",
    "            print()\n",
    "                \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(self.n_classes):\n",
    "            predictions.append(self.models[i].predict(X))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent each sample in Tucker form and store it in a list\n",
    "# algo = HOOI()\n",
    "algo = GLTD()\n",
    "rank = (4,2,2)\n",
    "X_tk = [algo.decompose(sample, rank=rank) for sample in X]\n",
    "\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tk, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# test_size = 0.25\n",
    "# k = int(len(X_tk) * (1. - test_size))\n",
    "\n",
    "# X_train, X_test = X_tk[:k], X_tk[k:]\n",
    "# y_train, y_test = y[:k], y[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - \n",
      "\n",
      "Classification accuracy (Train):\n",
      "[100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%, 100.00%]\n",
      "\n",
      "Classification accuracy (Test):\n",
      "[68.29%, 66.67%, 75.20%, 77.24%, 77.24%, 72.36%, 75.61%, 75.20%, 79.67%, 76.83%, 70.73%, 75.20%]\n",
      "\n",
      "Percentage of 1s (Test):\n",
      "[58.54%, 58.13%, 58.13%, 64.23%, 58.94%, 63.01%, 56.91%, 55.28%, 55.69%, 53.66%, 59.35%, 58.54%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialise classifier\n",
    "R = np.sum(rank) # number of base classifiers required per class\n",
    "n_classes = 1 if y.ndim == 1 else y.shape[1]\n",
    "\n",
    "base_clfs = []\n",
    "for _ in range(n_classes):\n",
    "    base_clfs.append([DecisionTreeClassifier() for _ in range(R)])\n",
    "\n",
    "grtel = GRTEL(base_clfs=base_clfs,\n",
    "              n_classes=n_classes,\n",
    "              probability=True,\n",
    "              verbose=False)\n",
    "\n",
    "\n",
    "# Train classifer\n",
    "grtel.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Scores\n",
    "score = grtel.score(X_train, y_train)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"\\nClassification accuracy (Train):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "score = grtel.score(X_test, y_test)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Test):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "print(\"Percentage of 1s (Test):\")\n",
    "print_1_percentage(y_test); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(84, 54, 0.6428571428571429),\n",
       " (101, 63, 0.6237623762376238),\n",
       " (90, 66, 0.7333333333333333),\n",
       " (87, 60, 0.6896551724137931),\n",
       " (101, 72, 0.7128712871287128),\n",
       " (80, 51, 0.6375),\n",
       " (100, 74, 0.74),\n",
       " (95, 72, 0.7578947368421053),\n",
       " (135, 97, 0.7185185185185186),\n",
       " (99, 79, 0.797979797979798),\n",
       " (96, 64, 0.6666666666666666),\n",
       " (78, 60, 0.7692307692307693)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(12):\n",
    "    results.append(downturn_confidence(y_test[:,i], grtel.models[i].predict(X_test)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(317, 317, 1.0),\n",
       " (307, 307, 1.0),\n",
       " (303, 303, 1.0),\n",
       " (263, 263, 1.0),\n",
       " (308, 308, 1.0),\n",
       " (284, 284, 1.0),\n",
       " (315, 315, 1.0),\n",
       " (320, 320, 1.0),\n",
       " (359, 359, 1.0),\n",
       " (308, 308, 1.0),\n",
       " (287, 287, 1.0),\n",
       " (265, 265, 1.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(12):\n",
    "    results.append(downturn_confidence(y_train[:,i], grtel.models[i].predict(X_train)))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "Grid Search:\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPerforming grid search for each base classifer and for each class\n",
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - \n",
      "\tTrain base classifiers with optimal hyperparameters\n",
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - \n",
      "\n",
      "Classification accuracy (Train):\n",
      "[95.39%, 100.00%, 99.73%, 97.29%, 98.51%, 98.78%, 99.32%, 99.32%, 99.59%, 97.02%, 91.87%, 99.46%]\n",
      "\n",
      "Classification accuracy (Test):\n",
      "[65.04%, 71.14%, 71.54%, 76.42%, 76.02%, 76.42%, 78.05%, 78.05%, 78.86%, 76.83%, 67.07%, 70.73%]\n",
      "\n",
      "Percentage of 1s (Test):\n",
      "[58.54%, 58.13%, 58.13%, 64.23%, 58.94%, 63.01%, 56.91%, 55.28%, 55.69%, 53.66%, 59.35%, 58.54%]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_features = ['auto', 'sqrt', None, 'log2']\n",
    "max_depth = list(range(10, 70, 10))\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 20, 30]\n",
    "min_samples_leaf = [1, 3, 5, 7, 12, 14]\n",
    "\n",
    "search_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "search_params = [search_grid for _ in range(R)]\n",
    "\n",
    "print(\"\\tPerforming grid search for each base classifer and for each class\")\n",
    "grtel.grid_search(X_train, y_train, search_params)\n",
    "\n",
    "print(\"\\tTrain base classifiers with optimal hyperparameters\")\n",
    "grtel.fit(X_train, y_train); print()\n",
    "\n",
    "score = grtel.score(X_train, y_train)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Train):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "score = grtel.score(X_test, y_test)\n",
    "score = score if n_classes > 1 else [score]\n",
    "print(\"Classification accuracy (Test):\")\n",
    "print_scores(score); print()\n",
    "\n",
    "print(\"Percentage of 1s (Test):\")\n",
    "print_1_percentage(y_test); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(96, 62, 0.6458333333333334),\n",
       " (105, 66, 0.6285714285714286),\n",
       " (84, 59, 0.7023809523809523),\n",
       " (69, 48, 0.6956521739130435),\n",
       " (82, 64, 0.7804878048780488),\n",
       " (77, 51, 0.6623376623376623),\n",
       " (83, 67, 0.8072289156626506),\n",
       " (103, 79, 0.7669902912621359),\n",
       " (122, 85, 0.6967213114754098),\n",
       " (89, 67, 0.7528089887640449),\n",
       " (74, 45, 0.6081081081081081),\n",
       " (39, 31, 0.7948717948717948)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(12):\n",
    "    results.append(downturn_confidence(y_test[:,i], grtel.models[i].predict(X_test)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(307, 275, 0.8957654723127035),\n",
       " (309, 306, 0.9902912621359223),\n",
       " (295, 294, 0.9966101694915255),\n",
       " (231, 222, 0.961038961038961),\n",
       " (292, 286, 0.9794520547945206),\n",
       " (258, 253, 0.9806201550387597),\n",
       " (300, 295, 0.9833333333333333),\n",
       " (313, 309, 0.987220447284345),\n",
       " (363, 348, 0.9586776859504132),\n",
       " (284, 272, 0.9577464788732394),\n",
       " (258, 227, 0.8798449612403101),\n",
       " (230, 229, 0.9956521739130435)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(12):\n",
    "    results.append(downturn_confidence(y_train[:,i], grtel.models[i].predict(X_train)))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
